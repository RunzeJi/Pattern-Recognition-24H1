{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OONmhPHxTCew"
      },
      "source": [
        "# Pattern Recognition 24H1\n",
        "#### Runze Ji, Jiashuo Tian, Ziqian Liu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08wd7jgWOOmk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_files_path = '../../PR/train'\n",
        "model_path = '/content/drive/MyDrive/PR/model.ptm'\n",
        "train_files = os.listdir(train_files_path)\n",
        "\n",
        "print(f'[PREPROC] Found {len(train_files)} Training Files\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "19GMj6YsOylz",
        "outputId": "d8d0c30f-0bfa-4665-8acc-9fabfae412b4"
      },
      "outputs": [],
      "source": [
        "all_labels = []\n",
        "\n",
        "train_files_pb = tqdm(train_files)\n",
        "train_files_pb.set_description('[preproc.loadCSV] Loading CSV Files...')\n",
        "\n",
        "for file in train_files_pb:\n",
        "    file_path = os.path.join(train_files_path, file)\n",
        "    data = pd.read_csv(file_path)\n",
        "    all_labels.extend(data['type'].unique())\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(all_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwxeI603PDzr",
        "outputId": "33580d52-3dee-42dc-89b1-ea42fe05649a"
      },
      "outputs": [],
      "source": [
        "X_all = []\n",
        "y_all = []\n",
        "\n",
        "train_files_pb = tqdm(train_files)\n",
        "train_files_pb.set_description('[preproc.transform] Transforming Data...')\n",
        "\n",
        "for file in train_files_pb:\n",
        "    file_path = os.path.join(train_files_path, file)\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    # 转换时间列，提取特征等\n",
        "    data['time'] = pd.to_datetime(data['time'])\n",
        "    data['hour'] = data['time'].dt.hour\n",
        "    data['day_of_week'] = data['time'].dt.dayofweek\n",
        "    data['month'] = data['time'].dt.month\n",
        "\n",
        "    # 使用转换后的标签\n",
        "    data['type_encoded'] = label_encoder.transform(data['type'])\n",
        "\n",
        "    X = data[['lat', 'lon', '速度', '方向', 'hour', 'day_of_week', 'month']]\n",
        "    y = data['type_encoded']\n",
        "\n",
        "    X_all.append(X)\n",
        "    y_all.append(y)\n",
        "\n",
        "# 将所有数据合并为一个大的 DataFrame\n",
        "X = pd.concat(X_all, ignore_index=True)\n",
        "y = pd.concat(y_all, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmR6JQPHPLyF"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLgbYJ7tPQet"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "class FishingVesselDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        \"\"\"\n",
        "        features: 特征数据，尺寸为 (n_samples, n_features)\n",
        "        labels: 标签数据，尺寸为 (n_samples,)\n",
        "        \"\"\"\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "# 假设 X_train, y_train, X_test, y_test 已经准备好了\n",
        "# 将数据转换为 PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# 创建 Dataset\n",
        "train_dataset = FishingVesselDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = FishingVesselDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# 创建 DataLoader\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce58116aPUvU"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FishingVesselNet(nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(FishingVesselNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_features, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        '''\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# 实例化模型\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = len(torch.unique(y_train_tensor)) # 假设所有类别都在训练集中出现过\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'[torch.cuda] Availability: {torch.cuda.is_available()}')\n",
        "\n",
        "model = FishingVesselNet(num_features, num_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAi6g6rMNavZ"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# 定义损失函数和优化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 训练模型\n",
        "num_epochs = 10\n",
        "\n",
        "train_loader_pb = tqdm(train_loader)\n",
        "train_loader_pb.set_description('[torch.train.epoch] Train Loader Step')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in train_loader_pb:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f' Epoch {epoch+1}, Loss: {loss.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPbM_G6VbGMj",
        "outputId": "4c79d340-5d35-405b-a329-14be3b741b5e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch : 100%|██████████| 269743/269743 [33:18<00:00, 134.94it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 5, Loss: 0.7565252780914307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train single epoch\n",
        "train_single_pb = tqdm(train_loader)\n",
        "train_single_pb.set_description('[torch.train.single] Training Single Epoch ')\n",
        "\n",
        "for inputs, labels in train_single_pb:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "epoch += 1\n",
        "print(f'[torch.train.step] Epoch {epoch+1}, Loss: {loss.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "401a0kdTPZx8",
        "outputId": "ec16a73b-1075-4e0a-8745-02bbb6c66c2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy:   0%|          | 0/179829 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 179829/179829 [04:32<00:00, 660.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test] Accuracy on test set: 65.13091973993303%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Test current accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "test_loader_pb = tqdm(test_loader)\n",
        "test_loader_pb.set_description('[torch.test] Testing Accuracy')\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader_pb:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'\\n[torch.test] Accuracy on test set: {100 * correct / total}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "eF6609JifcsB",
        "outputId": "ece78981-349a-4a97-a431-ebc37518e937"
      },
      "outputs": [],
      "source": [
        "# Evaluate Accuracy on each epoch\n",
        "import torch.optim as optim\n",
        "\n",
        "# 定义损失函数和优化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 训练模型\n",
        "num_epochs = 15\n",
        "\n",
        "epochs_pb = tqdm(range(num_epochs))\n",
        "epochs_pb.set_description('[torch.train] Training')\n",
        "\n",
        "for epoch in epochs_pb:\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'[torch.train.accuracy] Epoch {epoch+1}, Loss: {loss.item()}, Accuracy: {100 * correct / total}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5hXwW5vkpXv"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksa9cjPmmqTu"
      },
      "outputs": [],
      "source": [
        "torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9uoIN21nMUh"
      },
      "outputs": [],
      "source": [
        "model = FishingVesselNet(num_features, num_classes)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "checkpoint = torch.load(model_path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "\n",
        "model.eval()\n",
        "# - or -\n",
        "model.train()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
