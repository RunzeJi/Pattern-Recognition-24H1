{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OONmhPHxTCew"
      },
      "source": [
        "# Pattern Recognition 24H1\n",
        "#### Runze Ji, Jiashuo Tian, Ziqian Liu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Import necessary Modules\n",
        "* pandas\n",
        "* scikit-learn\n",
        "* itertools.islice\n",
        "* tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "08wd7jgWOOmk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from itertools import islice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Specify the parameters used in training the classifier:\n",
        "* Number of training files (TRAIN_FILES_COUNT)\n",
        "* Epochs (EPOCHS)\n",
        "* Path to train files (TRAIN_FILES_PATH)\n",
        "* Path to Model (MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[init] Found 18329 Training Files\n",
            "\n"
          ]
        }
      ],
      "source": [
        "TRAIN_FILES_COUNT = 18329\n",
        "TRAIN_FILES_OFFSET = 0\n",
        "EPOCHS = 20\n",
        "\n",
        "TRAIN_FILES_PATH = '../../PR/train'\n",
        "TEST_DATASET_PATH = '../../PR/test_dataset'\n",
        "MODEL_PATH = '../../PR/model3.ptm'\n",
        "LOGS_PATH = '../../PR/eval3.csv'\n",
        "\n",
        "TRAIN_FILES = os.listdir(TRAIN_FILES_PATH)\n",
        "TRAIN_FILES_END = TRAIN_FILES_COUNT + TRAIN_FILES_OFFSET\n",
        "NUMBER_OF_EPOCHS = 0\n",
        "print(f'[init] Found {len(TRAIN_FILES)} Training Files\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Slice training files and encode labels\n",
        "* All files containing datasets will be sliced in specified count, allowing separate training\n",
        "* Encode 'type'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "19GMj6YsOylz",
        "outputId": "d8d0c30f-0bfa-4665-8acc-9fabfae412b4"
      },
      "outputs": [],
      "source": [
        "print(f'[init] Reading from Index-{TRAIN_FILES_OFFSET} to Index-{TRAIN_FILES_END-1}')\n",
        "train_files_pb = tqdm(islice(TRAIN_FILES, TRAIN_FILES_OFFSET, TRAIN_FILES_END), '[preproc.loadCSV] Loading CSV Files...')\n",
        "\n",
        "all_labels = []\n",
        "\n",
        "for file in train_files_pb:\n",
        "    file_path = os.path.join(TRAIN_FILES_PATH, file)\n",
        "    data = pd.read_csv(file_path)\n",
        "    all_labels.extend(data['type'].unique())\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(all_labels)\n",
        "\n",
        "# 打印标签和对应的编码\n",
        "for label, encoded_label in zip(label_encoder.classes_, range(len(label_encoder.classes_))):\n",
        "    print(f\"Label: {label} --> Encoded Label: {encoded_label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Transforms dataframe and extend datatypes\n",
        "* Analyzes dataframe and extract features\n",
        "* Extend features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwxeI603PDzr",
        "outputId": "33580d52-3dee-42dc-89b1-ea42fe05649a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[preproc.transform] Transforming Data...:  13%|█▎        | 202/1500 [00:03<00:20, 63.78it/s]C:\\Users\\jirun\\AppData\\Local\\Temp\\ipykernel_1716\\1805563178.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  data['time'] = pd.to_datetime(data['time'])\n",
            "[preproc.transform] Transforming Data...: 100%|██████████| 1500/1500 [00:21<00:00, 69.66it/s]\n"
          ]
        }
      ],
      "source": [
        "X_all = []\n",
        "y_all = []\n",
        "\n",
        "train_files_pb = tqdm(islice(TRAIN_FILES, TRAIN_FILES_COUNT),'[preproc.transform] Transforming Data...', TRAIN_FILES_COUNT)\n",
        "\n",
        "for file in train_files_pb:\n",
        "    file_path = os.path.join(TRAIN_FILES_PATH, file)\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    # 转换时间列，提取特征等\n",
        "    data['time'] = pd.to_datetime(data['time'])\n",
        "    data['hour'] = data['time'].dt.hour\n",
        "    data['day_of_week'] = data['time'].dt.dayofweek\n",
        "    data['month'] = data['time'].dt.month\n",
        "\n",
        "    # 使用转换后的标签\n",
        "    data['type_encoded'] = label_encoder.transform(data['type'])\n",
        "\n",
        "    X = data[['lat', 'lon', '速度', '方向', 'hour', 'day_of_week', 'month']]\n",
        "    y = data['type_encoded']\n",
        "\n",
        "    X_all.append(X)\n",
        "    y_all.append(y)\n",
        "\n",
        "# 将所有数据合并为一个大的 DataFrame\n",
        "X = pd.concat(X_all, ignore_index=True)\n",
        "y = pd.concat(y_all, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KmR6JQPHPLyF"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define dataset structure\n",
        "* Create Datasets for training and verifying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XLgbYJ7tPQet"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "class FishingVesselDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        \"\"\"\n",
        "        features: 特征数据，尺寸为 (n_samples, n_features)\n",
        "        labels: 标签数据，尺寸为 (n_samples,)\n",
        "        \"\"\"\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "# 假设 X_train, y_train, X_test, y_test 已经准备好了\n",
        "# 将数据转换为 PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# 创建 Dataset\n",
        "train_dataset = FishingVesselDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = FishingVesselDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# 创建 DataLoader\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define Neural Network Structure, Loss Function, and  Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ce58116aPUvU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_features = 7\n",
            "num_classes = 3\n",
            "[torch.cuda] Availability: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jirun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FishingVesselNet(nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(FishingVesselNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_features, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.sigmoid(self.fc1(x))\n",
        "        x = F.sigmoid(self.fc2(x))\n",
        "        x = F.sigmoid(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# 实例化模型\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = len(torch.unique(y_train_tensor)) # 假设所有类别都在训练集中出现过\n",
        "\n",
        "print(f'num_features = {num_features}')\n",
        "print(f'num_classes = {num_classes}')\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'[torch.cuda] Availability: {torch.cuda.is_available()}')\n",
        "\n",
        "model = FishingVesselNet(num_features, num_classes).to(device)\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "# 定义损失函数和优化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load Pre-trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = FishingVesselNet(num_features, num_classes)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "checkpoint = torch.load(MODEL_PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "NUMBER_OF_EPOCHS = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "\n",
        "##model.eval()\n",
        "# - or -\n",
        "model.train()\n",
        "NUMBER_OF_EPOCHS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train a single epoch and evaluate accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPbM_G6VbGMj",
        "outputId": "4c79d340-5d35-405b-a329-14be3b741b5e"
      },
      "outputs": [],
      "source": [
        "# Train single epoch\n",
        "train_single_pb = tqdm(train_loader)\n",
        "train_single_pb.set_description(f'[torch.train.single] Training Single Epoch {NUMBER_OF_EPOCHS + 1}')\n",
        "\n",
        "for inputs, labels in train_single_pb:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "NUMBER_OF_EPOCHS += 1\n",
        "print(f'[torch.train.step] Epoch {NUMBER_OF_EPOCHS}, Loss: {loss.item()}, Total Number of Epochs: {NUMBER_OF_EPOCHS}')\n",
        "\n",
        "# Test current accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "test_loader_pb = tqdm(test_loader)\n",
        "test_loader_pb.set_description('[torch.test] Testing Accuracy')\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader_pb:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'\\n[torch.test] Accuracy on test set: {100 * correct / total}%')\n",
        "\n",
        "torch.save({\n",
        "            'epoch': NUMBER_OF_EPOCHS,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, MODEL_PATH)\n",
        "\n",
        "with open('../../PR/eval.csv', 'a') as eval_file:\n",
        "    eval_file.writelines(f'{NUMBER_OF_EPOCHS},{format(100 * correct / total, \".2f\")},{format(loss.item(), \".2f\")}\\n')\n",
        "    eval_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Evaluate Current Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "401a0kdTPZx8",
        "outputId": "ec16a73b-1075-4e0a-8745-02bbb6c66c2e"
      },
      "outputs": [],
      "source": [
        "# Test current accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "test_loader_pb = tqdm(test_loader)\n",
        "test_loader_pb.set_description('[torch.test] Testing Accuracy')\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader_pb:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'\\n[torch.test] Accuracy on test set: {100 * correct / total}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train Specified Number of Epochs and Evaluate Accuracy on each Epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "eF6609JifcsB",
        "outputId": "ece78981-349a-4a97-a431-ebc37518e937"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 21:   0%|          | 0/23095 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 21: 100%|██████████| 23095/23095 [01:48<00:00, 212.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 21, Loss: 0.886793851852417, Total Number of Epochs: 21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:27<00:00, 553.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:21, Loss:0.886793851852417, Accuracy:74.70279958025579%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 22: 100%|██████████| 23095/23095 [01:53<00:00, 203.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 22, Loss: 0.7707154154777527, Total Number of Epochs: 22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:30<00:00, 511.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:22, Loss:0.7707154154777527, Accuracy:75.03333800166843%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 23: 100%|██████████| 23095/23095 [01:53<00:00, 203.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 23, Loss: 0.7228807806968689, Total Number of Epochs: 23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:30<00:00, 497.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:23, Loss:0.7228807806968689, Accuracy:75.33261887509362%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 24: 100%|██████████| 23095/23095 [01:53<00:00, 203.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 24, Loss: 0.4244494140148163, Total Number of Epochs: 24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:29<00:00, 523.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:24, Loss:0.4244494140148163, Accuracy:75.46840653485724%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 25: 100%|██████████| 23095/23095 [01:53<00:00, 203.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 25, Loss: 0.410101056098938, Total Number of Epochs: 25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:28<00:00, 545.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:25, Loss:0.410101056098938, Accuracy:75.75205863428872%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 26: 100%|██████████| 23095/23095 [01:50<00:00, 209.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 26, Loss: 0.4149444103240967, Total Number of Epochs: 26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:29<00:00, 521.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:26, Loss:0.4149444103240967, Accuracy:75.57385001654214%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 27: 100%|██████████| 23095/23095 [01:49<00:00, 211.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 27, Loss: 0.6505568623542786, Total Number of Epochs: 27\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:28<00:00, 535.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:27, Loss:0.6505568623542786, Accuracy:75.95107178884511%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 28: 100%|██████████| 23095/23095 [01:50<00:00, 209.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 28, Loss: 0.45645949244499207, Total Number of Epochs: 28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:28<00:00, 545.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:28, Loss:0.45645949244499207, Accuracy:75.74201156529276%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 29: 100%|██████████| 23095/23095 [01:50<00:00, 208.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 29, Loss: 0.6424070000648499, Total Number of Epochs: 29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:28<00:00, 545.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:29, Loss:0.6424070000648499, Accuracy:75.39198791916067%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 30: 100%|██████████| 23095/23095 [01:57<00:00, 197.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 30, Loss: 0.5375939607620239, Total Number of Epochs: 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:28<00:00, 537.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:30, Loss:0.5375939607620239, Accuracy:75.4791640026711%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 31: 100%|██████████| 23095/23095 [02:02<00:00, 189.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 31, Loss: 0.5349096655845642, Total Number of Epochs: 31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:28<00:00, 537.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:31, Loss:0.5349096655845642, Accuracy:74.97102587678437%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 32: 100%|██████████| 23095/23095 [02:00<00:00, 191.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 32, Loss: 0.46722084283828735, Total Number of Epochs: 32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:31<00:00, 493.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:32, Loss:0.46722084283828735, Accuracy:75.77732853509674%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 33: 100%|██████████| 23095/23095 [01:52<00:00, 204.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 33, Loss: 0.4147057831287384, Total Number of Epochs: 33\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:29<00:00, 530.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:33, Loss:0.4147057831287384, Accuracy:75.04866231902591%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 34: 100%|██████████| 23095/23095 [02:02<00:00, 188.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 34, Loss: 0.684242844581604, Total Number of Epochs: 34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:31<00:00, 482.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:34, Loss:0.684242844581604, Accuracy:76.20336485474374%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 35: 100%|██████████| 23095/23095 [02:00<00:00, 191.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 35, Loss: 0.5474082231521606, Total Number of Epochs: 35\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:29<00:00, 521.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:35, Loss:0.5474082231521606, Accuracy:76.02109681518061%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 36: 100%|██████████| 23095/23095 [01:54<00:00, 200.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 36, Loss: 0.5344355702400208, Total Number of Epochs: 36\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:31<00:00, 482.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:36, Loss:0.5344355702400208, Accuracy:74.63470277928315%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 37: 100%|██████████| 23095/23095 [01:57<00:00, 196.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 37, Loss: 0.5186828374862671, Total Number of Epochs: 37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:28<00:00, 544.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:37, Loss:0.5186828374862671, Accuracy:75.98263379346879%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 38: 100%|██████████| 23095/23095 [02:01<00:00, 190.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 38, Loss: 0.7173260450363159, Total Number of Epochs: 38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:29<00:00, 518.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:38, Loss:0.7173260450363159, Accuracy:75.33525749927438%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 39: 100%|██████████| 23095/23095 [02:02<00:00, 188.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 39, Loss: 0.6455652117729187, Total Number of Epochs: 39\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:29<00:00, 523.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:39, Loss:0.6455652117729187, Accuracy:75.94965099120932%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.train.single] Training Single Epoch 40: 100%|██████████| 23095/23095 [01:58<00:00, 194.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.train.step] Epoch 40, Loss: 0.4806520342826843, Total Number of Epochs: 40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[torch.test] Testing Accuracy: 100%|██████████| 15397/15397 [00:33<00:00, 466.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[torch.test.result] Epoch:40, Loss:0.4806520342826843, Accuracy:76.22264710837236%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train Specified Number of Epochs and Evaluate Accuracy on each Epoch\n",
        "for ep in range(EPOCHS):\n",
        "    train_single_pb = tqdm(train_loader)\n",
        "    train_single_pb.set_description(f'[torch.train.single] Training Single Epoch {NUMBER_OF_EPOCHS + 1}')\n",
        "\n",
        "    for inputs, labels in train_single_pb:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    NUMBER_OF_EPOCHS += 1\n",
        "    print(f'[torch.train.step] Epoch {NUMBER_OF_EPOCHS}, Loss: {loss.item()}, Total Number of Epochs: {NUMBER_OF_EPOCHS}')\n",
        "\n",
        "    # Test current accuracy\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    test_loader_pb = tqdm(test_loader, '[torch.test] Testing Accuracy')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader_pb:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'\\n[torch.test.result] Epoch:{NUMBER_OF_EPOCHS}, Loss:{loss.item()}, Accuracy:{100 * correct / total}%\\n')\n",
        "\n",
        "    torch.save({\n",
        "                'epoch': NUMBER_OF_EPOCHS,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "    with open(LOGS_PATH, 'a') as eval_file:\n",
        "        eval_file.writelines(f'{NUMBER_OF_EPOCHS},{format(100 * correct / total, \".2f\")},{format(loss.item(), \".2f\")}\\n')\n",
        "        eval_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Model Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksa9cjPmmqTu"
      },
      "outputs": [],
      "source": [
        "torch.save({\n",
        "            'epoch': NUMBER_OF_EPOCHS,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TEST_DATASET_PATH = '../../PR/test_dataset'\n",
        "MODEL_PATH = '../../PR/model2.ptm'\n",
        "TEST_FILES = os.listdir(TEST_DATASET_PATH)\n",
        "\n",
        "print(f'[verify] Found {len(TEST_FILES)} Test Files\\n')\n",
        "\n",
        "X_verify_all = []\n",
        "\n",
        "test_files_pb = tqdm(TEST_FILES,'[preproc.transform] Transforming Data...')\n",
        "\n",
        "for file in test_files_pb:\n",
        "    file_path = os.path.join(TEST_DATASET_PATH, file)\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    # 转换时间列，提取特征等\n",
        "    data['time'] = pd.to_datetime(data['time'])\n",
        "    data['hour'] = data['time'].dt.hour\n",
        "    data['day_of_week'] = data['time'].dt.dayofweek\n",
        "    data['month'] = data['time'].dt.month\n",
        "\n",
        "    X_verify = data[['渔船ID', 'lat', 'lon', '速度', '方向', 'hour', 'day_of_week', 'month']]\n",
        "    #X_test = data[['lat', 'lon', '速度', '方向', 'hour', 'day_of_week', 'month']]\n",
        "\n",
        "    X_verify_all.append(X_verify)\n",
        "\n",
        "# 将所有数据合并为一个大的 DataFrame\n",
        "X_verify = pd.concat(X_verify_all, ignore_index=True)\n",
        "X_verify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_verify_tensor = torch.tensor(X_verify[['lat', 'lon', '速度', '方向', 'hour', 'day_of_week', 'month']].values, dtype=torch.float32)\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, features):\n",
        "        self.features = features\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx]\n",
        "    \n",
        "verify_dataset = TestDataset(X_verify_tensor)\n",
        "verify_loader = DataLoader(dataset=verify_dataset, batch_size=64, shuffle=False)\n",
        "    \n",
        "# 实例化模型\n",
        "num_features = X_verify.drop('渔船ID', axis=1).shape[1]\n",
        "num_classes = 3\n",
        "\n",
        "import torch.optim as optim\n",
        "model = FishingVesselNet(num_features, num_classes)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "checkpoint = torch.load(MODEL_PATH)\n",
        "\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = []\n",
        "verify_loader_pb = tqdm(verify_loader, '[torch.test] Testing Accuracy')\n",
        "with torch.no_grad():\n",
        "    for inputs in verify_loader_pb:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        predictions.extend(predicted.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ids = X_verify['渔船ID'].values\n",
        "\n",
        "# 创建一个DataFrame来存储预测结果\n",
        "predictions_df = pd.DataFrame({\n",
        "    '渔船ID': ids,\n",
        "    'type': predictions\n",
        "})\n",
        "\n",
        "# 显示DataFrame的前几行以确认\n",
        "predictions_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_replaced = predictions_df[['渔船ID', 'type']].replace({0:\"刺网\", 1:\"围网\", 2:\"拖网\"})\n",
        "X_replaced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_final = X_replaced.drop_duplicates(subset='渔船ID', keep='first')\n",
        "X_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_final.to_csv('../../PR/submissions/nn/submission_nn.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
